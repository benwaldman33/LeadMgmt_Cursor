# LeadMgmt System Help & FAQ

## ðŸ†• Latest Updates - January 2, 2025

### ðŸš¨ **CRITICAL DATABASE CONFIGURATION INVESTIGATION: Data Loss and Setup Clarification**

**Problem**: User reported missing leads, campaigns, and workflows after switching to Docker setup, leading to extensive investigation into database configuration and data persistence issues.

**Root Cause Analysis**:
- **Database Evolution History**: System evolved through multiple database configurations:
  1. **Phase 1**: SQLite (`dev.db`) - Local development
  2. **Phase 2**: PostgreSQL (`leadscoring_dev`) - Docker setup
  3. **Phase 3**: PostgreSQL (`leadmgmt`) - Current configuration
- **Data Loss Event**: During transition from `leadscoring_dev` to `leadmgmt`, existing user data was lost
- **Configuration Confusion**: Multiple database configurations existed simultaneously, causing confusion about which database was active
- **Backup Analysis**: Backup files contained only schema definitions, not actual data, indicating data was already lost when backups were created

**Current Database Configuration (Verified)**:
- **Database Type**: PostgreSQL 15 (Alpine Linux) running in Docker
- **Database Name**: `leadmgmt`
- **Container**: `leadmgmt_cursor-postgres-1`
- **Access**: `localhost:5433` (mapped from container's 5432)
- **ORM**: Prisma configured for PostgreSQL
- **Data Status**: 6 users (from seeding), 0 leads/campaigns/workflows (data lost during transition)

**Files Involved**:
- `docker-compose.yml` - PostgreSQL service configuration
- `backend/prisma/schema.prisma` - Database schema and provider configuration
- `backend/.env` - Database connection string
- `backup-leadmgmt.ps1` - Backup script (created after data loss issue)

**Resolution**:
- âœ… Confirmed current database is PostgreSQL 15 in Docker
- âœ… Verified Prisma is properly configured for PostgreSQL
- âœ… Confirmed system is working correctly with current setup
- âœ… Identified that user data was lost during database name transition
- âŒ Data recovery not possible (backups contain only schema, no data)

**Prevention Measures**:
- Updated all documentation to clarify database configuration
- Added comprehensive database setup guide
- Enhanced backup procedures to include data verification
- Added troubleshooting section for database issues

### ðŸš¨ **CRITICAL INTEGRATION: Business Rules System & Database Configuration**

**Problem**: Comprehensive business rules system integration encountered multiple technical challenges including database connectivity issues, Docker networking problems, and frontend-backend communication issues that prevented the business rules functionality from working properly.

**Root Cause Analysis**:
- **Database Schema Migration**: New `RuleExecutionLog` table required for business rules audit trail
- **Docker Configuration**: Database name mismatch between Docker (`leadscoring_dev`) and Prisma (`leadmgmt`) configuration
- **Network Connectivity**: Docker networking issues prevented host machine from accessing database containers
- **Authentication Issues**: 500 errors on login attempts due to database connectivity problems
- **Frontend Integration**: "Create Rule" button non-functional due to backend communication failures

**Solutions Implemented**:
- **Business Rules Integration**: Complete integration across lead lifecycle events (creation, updates, scoring)
- **Database Configuration Fix**: Aligned Docker database name from `leadscoring_dev` to `leadmgmt`
- **Network Resolution**: Fixed port mapping (Docker: `postgres:5432`, Host: `localhost:5433`) and authentication credentials
- **Schema Migration Success**: Successfully applied `RuleExecutionLog` model to database
- **User Authentication**: Resolved login issues and created SUPER_ADMIN user (`admin@bbds.com` / `admin123`)
- **Frontend Enhancement**: Added comprehensive debug logging and improved error handling

**Status**: âœ… **FULLY INTEGRATED** - Business rules system now fully functional with complete integration across lead lifecycle

**Business Rules Integration Points**:
```typescript
// Lead Creation - Rules evaluate automatically
await RuleExecutionService.executeRulesForLead(lead.id, 'created', {
  campaignId: lead.campaignId,
  industry: lead.industry,
  companyName: lead.companyName,
  domain: lead.domain
});

// Lead Updates - Rules evaluate on changes
await RuleExecutionService.executeRulesForLead(lead.id, 'updated', {
  previousStatus: oldLead?.status,
  newStatus: lead.status,
  assignedToChanged: oldLead?.assignedToId !== lead.assignedToId
});

// Pipeline Scoring - Rules evaluate after AI scoring
await RuleExecutionService.executeRulesForLead(lead.id, 'scored', {
  score: scoringResult.totalScore,
  confidence: scoringResult.confidence,
  campaignId: campaignId,
  pipelineJobId: jobId,
  industry: industry
});

// Manual Scoring - Rules evaluate after manual scoring
await RuleExecutionService.executeRulesForLead(leadId, 'scored', {
  totalScore: scoringResult.totalScore,
  confidence: scoringResult.confidence,
  scoringModelVersion: '1.0'
});
```

### âœ… **RESOLVED: GitHub Push Protection & API Key Security**

**Problem**: GitHub was blocking all code pushes due to detected API keys in the repository, preventing deployment and collaboration.

**Root Cause**: Legacy utility scripts contained hardcoded API keys that were committed to the repository history.

**Solution**: 
- Removed API key files from entire Git history using `git filter-branch`
- Updated `.gitignore` to prevent future API key commits
- Verified existing API key management system is working correctly
- Preserved all development work while ensuring security

**Status**: âœ… **FIXED** - Repository is now secure and pushes work normally

### ðŸ” **API Key Security Best Practices**

**How API Keys Are Managed**:
- API keys are stored in environment variables (`.env` file)
- Database storage with AES-256-CBC encryption as fallback
- No hardcoded keys in application code
- Proper key rotation and management capabilities

**For Developers**:
- Never commit API keys to the repository
- Use environment variables for all sensitive data
- Test files should use placeholder values like "your-api-key-here"
- Utility scripts should be excluded from version control

## Previous Updates - September 28, 2025

### âœ… **RESOLVED: AI Discovery Conversation ID Display Issue**

**Problem**: AI conversations were showing database IDs (like "cmg2upxjz000d6429mbhbf7y1") instead of readable industry names.

**Root Cause**: The conversation message endpoint was missing ID resolution logic that existed in other AI Discovery features.

**Solution**: 
- Added ID resolution to conversation messages endpoint
- AI now receives proper industry names like "Plant-Based Protein Manufacturing"
- Consistent behavior across all AI Discovery features

**Status**: âœ… **FIXED** - Conversations now show proper industry names

### âœ… **RESOLVED: Leads Page 400 Bad Request Error**

**Problem**: Leads page was failing to load with 400 Bad Request errors.

**Root Cause**: Frontend was sending filter data in wrong format (strings instead of arrays for status, strings instead of Date objects for dates).

**Solution**: 
- Updated frontend to send correct data types
- Enhanced filter validation and error handling
- Improved data type consistency

**Status**: âœ… **FIXED** - Leads page now loads correctly

### âœ… **ENHANCED: Scoring Model Industry Selection**

**Problem**: Users couldn't create scoring models for AI Discovery industries (like "Plant-Based Protein Manufacturing") due to limited 5-option dropdown.

**Solution**: 
- **Dynamic Industry List**: Now includes all AI Discovery industries
- **Custom Input**: Enter any industry name manually
- **Auto-Detection**: Automatically set industry from selected campaign
- **Visual Indicators**: Icons show data source (database vs hardcoded)

**Status**: âœ… **ENHANCED** - Unlimited industry support for scoring models

### âœ… **RESOLVED: Customer Search Returning 0 Results** (Previous Fix)

**Problem**: AI Discovery customer search was consistently returning 0 results despite having a robust AI search system.

**Root Cause**: Frontend was passing database IDs (UUIDs) to the backend, but the AI needed human-readable names. The AI was receiving prompts like "Search for customers in uuid-123 / uuid-456" instead of "Search for customers in Healthcare / Medical Devices".

**Solution**: 
- Backend now resolves industry and product vertical IDs to actual names before sending to AI
- Frontend displays proper names in all notifications and messages
- Enhanced notification system with better close buttons and accessibility

**Status**: âœ… **FIXED** - Customer search now returns actual results

---

## ðŸ¢ Business Rules System

### How do business rules work?
Business rules automate actions based on defined conditions. The system evaluates rules automatically during key lead lifecycle events:

1. **Lead Creation**: Rules evaluate when new leads are created
2. **Lead Updates**: Rules trigger on status changes or assignment modifications  
3. **Pipeline Processing**: Rules execute after AI scoring completion
4. **Manual Scoring**: Rules evaluate after manual lead scoring operations

### What actions can business rules perform?
**Assignment Actions**:
- **Target**: `user` or `team`
- **Value**: User ID or Team ID for assignment

**Status Change Actions**:
- **Target**: N/A (automatic)
- **Value**: New status (NEW, CONTACTED, QUALIFIED, etc.)

**Scoring Actions**:
- **Target**: N/A (automatic)
- **Value**: Score number for lead

**Notification Actions**:
- **Target**: Notification recipient
- **Value**: Notification message

**Enrichment Actions**:
- **Target**: Data field to enrich
- **Value**: Data source or enrichment instruction

### How do I create a business rule?

1. **Navigate to Business Rules**: Go to Admin â†’ Business Rules
2. **Create New Rule**: Click "Create Rule" button
3. **Define Conditions**: Set conditions for when the rule should trigger
4. **Configure Actions**: Define what actions will be performed
5. **Set Trigger Events**: Choose when rules should evaluate (created, updated, scored)
6. **Save & Activate**: Save the rule and it will automatically execute

**Rule Creation Example**:
```
Condition: Lead status equals "NEW" AND company name contains "Technology"
Actions: Assign to user "Sales Rep A", Set status to "CONTACTED"
Trigger: When lead is created or updated
```

### Troubleshooting Business Rules

**"Create Rule" button not working**:
1. **Check Database Connection**: Ensure PostgreSQL container is running (`docker-compose ps`)
2. **Verify Docker Configuration**: Check database name alignment in docker-compose.yml
3. **Check Environment**: Ensure DATABASE_URL is properly configured
4. **Check Console**: Look for JavaScript errors in browser console
5. **Verify Authentication**: Ensure you're logged in as SUPER_ADMIN or ADMIN

**Rules not executing on lead events**:
1. **Check Rule Status**: Ensure rules are enabled and not in draft mode
2. **Verify Conditions**: Review rule conditions match the lead data
3. **Check Logs**: Review backend logs for rule execution errors
4. **Verify Integration**: Confirm rule service is properly integrated

### Docker Configuration Issues

**Database Connection Problems**:
```bash
# Check Docker status
docker-compose ps

# Check database connectivity
docker exec leadmgmt_cursor-postgres-1 psql -U dev -d leadmgmt -c "SELECT 1"

# Restart services
docker-compose down
docker-compose up -d
```

**Common Docker Issues**:
- **Port Conflicts**: Ensure port 5433 (host) and 5432 (container) are not in use
- **Database Name**: Must be `leadmgmt` in both Docker and Prisma configuration
- **Authentication**: Use `dev:devpass` credentials in both environments
- **Volume Data**: Database data persists in Docker volumes

**Access Credentials**:
- **Super Admin**: `admin@bbds.com` / `admin123`
- **Database**: `dev:devpass` for PostgreSQL
- **Container Access**: `docker exec -it leadmgmt_cursor-backend-1 bash`

## ðŸ¤– AI Discovery System

### How does AI Discovery work?

AI Discovery is a multi-step process that helps you find potential customers:

1. **Industry Discovery**: Enter your business description and AI suggests relevant industries
2. **Product Vertical Selection**: Choose specific product categories within your industry
3. **Customer Search**: AI searches for real companies that could be interested in your product
4. **Lead Generation**: Process discovered companies into your lead pipeline

### Why is my customer search returning 0 results?

**Most Common Causes:**
1. **AI Configuration Issues**: Check that your AI engines are properly configured
2. **Database Connectivity**: Ensure the database is running and accessible
3. **Operation Mappings**: Verify that AI engines are mapped to the AI_DISCOVERY operation

**Troubleshooting Steps:**
1. Check the Service Configuration page for AI engine status
2. Verify database connection in the backend logs
3. Ensure operation mappings exist for AI_DISCOVERY
4. Check browser console for error messages

### How do I configure AI engines for discovery?

1. Go to **Service Configuration** (Admin only)
2. Add or edit AI engines (Claude, OpenAI, Grok)
3. Set proper API keys and model names
4. Ensure engines are mapped to AI_DISCOVERY operation
5. Set priorities for failover order

### How do I create scoring models for any industry?

**New Enhanced Process**:
1. Go to **Scoring Models** â†’ **Create New Model**
2. **Choose your input method**:
   - **Select from List**: Choose from all AI Discovery industries + hardcoded options
   - **Enter Custom**: Type any industry name manually
   - **Auto-detect**: Select a campaign to automatically set the industry
3. **Visual Indicators**: 
   - ðŸ“Š = Database industry (from AI Discovery)
   - ðŸ”§ = Hardcoded industry (legacy support)
4. **Complete the form** with your scoring criteria
5. **Save** - Your model is now available for any industry!

**Benefits**:
- âœ… Unlimited industry support
- âœ… Seamless integration with AI Discovery
- âœ… Multiple input methods for flexibility
- âœ… Backward compatibility with existing models

### What industries can AI Discovery analyze?

AI Discovery can analyze any industry that the AI engines can understand. Common industries include:
- Healthcare & Medical
- Manufacturing & Industrial
- Technology & Software
- Financial Services
- Construction & Real Estate
- Food & Beverage
- And many more...

### How accurate are the customer search results?

The system uses a multi-tier search strategy:
1. **Primary Search**: Specific criteria with exact industry/product vertical match
2. **Broader Search**: Expanded criteria if primary search returns no results
3. **Industry-Specific Search**: Focus on industry characteristics as final fallback

This maximizes the chances of finding relevant customers while maintaining accuracy.

---

## ðŸ”§ Technical Troubleshooting

### Database Connection Issues

**Symptoms:**
- AI Discovery shows "Fallback Analysis"
- Service Configuration shows connection errors
- Backend logs show database connection failures

**Solutions:**
1. **Check Docker Status**: Ensure PostgreSQL container is running
   ```bash
   docker-compose ps
   ```

2. **Restart Database**: Restart the PostgreSQL service
   ```bash
   docker-compose restart postgres
   ```

3. **Check Environment Variables**: Verify DATABASE_URL in .env file
   ```bash
   # For Docker
   DATABASE_URL="postgresql://dev:devpass@postgres:5432/leadscoring_dev"
   
   # For Local Development
   DATABASE_URL="postgresql://dev:devpass@localhost:5433/leadscoring_dev"
   ```

### AI Engine Configuration Issues

**Symptoms:**
- AI Discovery fails with configuration errors
- Service Configuration shows invalid model names
- API calls return 404 or authentication errors

**Solutions:**
1. **Update Model Names**: Use current model names
   - Claude: `claude-sonnet-4-20250514`
   - OpenAI: `gpt-4` or `gpt-3.5-turbo`
   - Grok: Check current model availability

2. **Verify API Keys**: Ensure API keys are valid and have proper permissions

3. **Check Operation Mappings**: Verify AI engines are mapped to AI_DISCOVERY operation

### Notification System Issues

**Symptoms:**
- Notifications can't be closed
- Notifications show database IDs instead of names
- Toast notifications appear but don't respond to clicks

**Solutions:**
1. **Refresh Browser**: Clear browser cache and refresh
2. **Check Console**: Look for JavaScript errors in browser console
3. **Restart Frontend**: Restart the frontend development server

### Frontend-Backend Communication Issues

**Symptoms:**
- API calls return 401 Unauthorized
- Frontend can't connect to backend
- Authentication tokens not working

**Solutions:**
1. **Check Vite Proxy**: Ensure VITE_API_URL is set to `/api`
2. **Verify Authentication**: Check that user is properly logged in
3. **Check Token Storage**: Verify localStorage contains `bbds_access_token`

---

## ðŸ“Š Performance Optimization

### Improving AI Discovery Performance

1. **Database Optimization**:
   - Ensure proper indexes on industry and product vertical tables
   - Monitor query performance for ID resolution
   - Consider caching frequently accessed data

2. **AI API Optimization**:
   - Use appropriate model sizes for different tasks
   - Implement request batching where possible
   - Monitor API rate limits and quotas

3. **Frontend Optimization**:
   - Minimize unnecessary re-renders
   - Implement virtual scrolling for large result sets
   - Cache resolved names to reduce database queries

### Monitoring System Performance

1. **Backend Logs**: Monitor for errors and performance issues
2. **Database Metrics**: Track query performance and connection usage
3. **AI API Usage**: Monitor rate limits and response times
4. **Frontend Performance**: Use browser dev tools to identify bottlenecks

---

## ðŸ” Security & Authentication

### API Key Management

**Best Practices:**
1. **Secure Storage**: Store API keys in environment variables, never in code
2. **Key Rotation**: Regularly rotate API keys for security
3. **Access Control**: Limit API key permissions to minimum required
4. **Monitoring**: Monitor API key usage for unusual activity

**Configuration:**
```bash
# .env file
CLAUDE_API_KEY=your_claude_api_key
OPENAI_API_KEY=your_openai_api_key
GROK_API_KEY=your_grok_api_key
```

### User Authentication

**Token Management:**
1. **Automatic Expiration**: Tokens expire after configured time
2. **Secure Storage**: Tokens stored in localStorage with proper security
3. **Role-Based Access**: Different user roles have different permissions

**Troubleshooting:**
1. Clear browser localStorage if authentication issues persist
2. Check backend logs for authentication errors
3. Verify JWT_SECRET is properly configured

---

## ðŸš€ Advanced Features

### Custom AI Prompts

You can customize AI prompts for better results:

1. **Industry Discovery**: Modify prompts to focus on specific criteria
2. **Customer Search**: Adjust search parameters for better targeting
3. **Response Parsing**: Customize how AI responses are processed

### Integration with Lead Pipeline

**Workflow:**
1. Discover customers using AI Discovery
2. Review and filter results
3. Send to lead pipeline for enrichment
4. Process enriched leads for sales outreach

**Configuration:**
- Set up web scraping for discovered companies
- Configure lead scoring models
- Define enrichment workflows

### Service Configuration Management

**Advanced Features:**
1. **Priority Management**: Set failover order for AI engines
2. **Usage Limits**: Configure rate limits and quotas
3. **Performance Monitoring**: Track service performance and costs
4. **Testing**: Test service configurations before use

---

## ðŸ“š Developer Resources

### API Documentation

**AI Discovery Endpoints:**
- `POST /api/ai-discovery/discover-industries` - Discover industries
- `GET /api/ai-discovery/industries/:id/verticals` - Get product verticals
- `POST /api/ai-discovery/search-customers` - Search for customers
- `POST /api/ai-discovery/customer-insights` - Generate customer insights

**Service Configuration Endpoints:**
- `GET /api/service-configuration/providers` - List service providers
- `POST /api/service-configuration/providers` - Create service provider
- `PUT /api/service-configuration/providers/:id` - Update service provider
- `POST /api/service-configuration/providers/:id/test` - Test service provider

### Database Schema

**Key Tables:**
- `Industry` - Industry information
- `ProductVertical` - Product categories within industries
- `CustomerType` - Customer segments for product verticals
- `ServiceProvider` - AI engines and services
- `OperationServiceMapping` - Links services to operations

### Debugging Tools

**Built-in Diagnostics:**
1. **Service Configuration Page**: Test AI engine connectivity
2. **Browser Console**: Frontend error logging
3. **Backend Logs**: Server-side error tracking
4. **Database Queries**: Direct database access for troubleshooting

**Custom Scripts:**
- `check-database-config.js` - Verify database configuration
- `check-operation-mappings.js` - Check operation mappings
- `test-ai-discovery.js` - Test AI discovery functionality

---

## ðŸ†˜ Getting Help

### Support Channels

1. **Documentation**: Check this FAQ and other documentation files
2. **Logs**: Review backend and frontend logs for error details
3. **Console**: Check browser console for JavaScript errors
4. **Database**: Direct database queries for data verification

### Common Error Messages

**"No AI engines available for operation: AI_DISCOVERY"**
- Solution: Check operation mappings in Service Configuration

**"Database connection failed"**
- Solution: Verify Docker containers are running and database is accessible

**"Invalid API key"**
- Solution: Update API keys in Service Configuration

**"Model not found"**
- Solution: Update to current model names in Service Configuration

**"400 Bad Request" on Leads page**
- Solution: This has been fixed - refresh the page. If it persists, check browser console for details

**"Campaign not showing in Pipeline dropdown"**
- Solution: Campaigns must have a scoring model assigned. Create a scoring model first, then assign it to the campaign

**"AI showing database IDs instead of industry names"**
- Solution: This has been fixed - AI conversations now show proper industry names

## Database Troubleshooting

### Database Configuration Verification
**Current Configuration**:
- **Database Type**: PostgreSQL 15 (Alpine Linux) in Docker
- **Database Name**: `leadmgmt`
- **Connection**: `postgresql://dev:devpass@postgres:5432/leadmgmt`
- **Port Mapping**: `localhost:5433` (host) â†’ `5432` (container)
- **Volume Data**: Database data persists in Docker volumes

### Database Troubleshooting Commands
**Check Database Status**:
```bash
# Check running containers
docker-compose ps

# Check database connection
docker exec leadmgmt_cursor-postgres-1 psql -U dev -d leadmgmt -c "SELECT COUNT(*) FROM users;"

# Check backend environment
docker exec leadmgmt_cursor-backend-1 env | grep DATABASE

# Check database data
docker exec leadmgmt_cursor-postgres-1 psql -U dev -d leadmgmt -c "SELECT COUNT(*) as user_count FROM users; SELECT COUNT(*) as lead_count FROM leads; SELECT COUNT(*) as campaign_count FROM campaigns;"
```

**Verify Database Configuration**:
```bash
# Check Prisma schema
cat backend/prisma/schema.prisma | grep -A 3 "datasource db"

# Check Docker Compose configuration
cat docker-compose.yml | grep -A 10 "postgres:"

# Check environment variables
docker exec leadmgmt_cursor-backend-1 env | grep -E "(DATABASE|POSTGRES)"
```

### Common Database Issues

**Issue**: "Database not found" or "Connection refused"
**Solution**: 
1. Check if Docker containers are running: `docker-compose ps`
2. Restart database: `docker-compose restart postgres`
3. Check database logs: `docker-compose logs postgres`

**Issue**: "Schema out of sync" or migration errors
**Solution**:
1. Generate Prisma client: `npx prisma generate`
2. Push schema changes: `npx prisma db push`
3. Check for schema conflicts in `backend/prisma/schema.prisma`

**Issue**: "Missing data" or "Empty tables"
**Solution**:
1. Verify data exists: Use troubleshooting commands above
2. Check if data was lost during database transitions
3. Restore from backup if available (see backup procedures)

### Database Backup and Recovery

**Create Backup**:
```bash
# Create full database backup
docker exec leadmgmt_cursor-postgres-1 pg_dump -U dev -d leadmgmt > backup_$(date +%Y%m%d_%H%M%S).sql

# Create backup with data verification
docker exec leadmgmt_cursor-postgres-1 psql -U dev -d leadmgmt -c "SELECT COUNT(*) FROM users; SELECT COUNT(*) FROM leads; SELECT COUNT(*) FROM campaigns;" > data_check_$(date +%Y%m%d_%H%M%S).txt
```

**Restore Backup**:
```bash
# Restore from backup file
docker exec -i leadmgmt_cursor-postgres-1 psql -U dev -d leadmgmt < backup_file.sql
```

### Reporting Issues

When reporting issues, please include:
1. **Error Message**: Exact error text
2. **Steps to Reproduce**: Detailed steps to recreate the issue
3. **Environment**: Browser, OS, and system details
4. **Logs**: Relevant backend and frontend logs
5. **Screenshots**: Visual evidence of the issue
6. **Database Status**: Output from troubleshooting commands above

---

## ðŸ“ˆ System Status

### Current Status: âœ… **OPERATIONAL**

**All Systems Working:**
- âœ… AI Discovery Customer Search
- âœ… AI Discovery Conversations (with proper industry names)
- âœ… Service Configuration Management
- âœ… Database Connectivity
- âœ… Authentication & Authorization
- âœ… Notification System
- âœ… Web Scraping & Enrichment
- âœ… Leads Page (no more 400 errors)
- âœ… Scoring Model Creation (unlimited industries)

### Recent Fixes (2025-09-28)
- âœ… Fixed AI Discovery conversation ID display issue
- âœ… Fixed Leads page 400 Bad Request error
- âœ… Enhanced scoring model industry selection with unlimited support
- âœ… Added dynamic industry list integration
- âœ… Added custom industry input capability
- âœ… Added campaign auto-detection for scoring models

### Previous Fixes (2025-08-31)
- âœ… Fixed customer search returning 0 results
- âœ… Enhanced notification system with proper close buttons
- âœ… Improved ID resolution for better AI prompts
- âœ… Added comprehensive error handling and logging

### Known Issues
- None currently identified

### Planned Improvements
1. **Performance Monitoring**: Real-time system metrics
2. **Advanced Caching**: Redis-based caching for better performance
3. **Enhanced Analytics**: Detailed usage and performance analytics
4. **Mobile Optimization**: Better mobile device support

---

*This help document is maintained by the development team and updated with each system release. For the latest information, check the CHANGELOG.md and engineering-log.md files.*
